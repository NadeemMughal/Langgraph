{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NadeemMughal/Langgraph/blob/main/LLM_To_Email_Langgraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxeSsCoMGAIX",
        "outputId": "a14722f0-59fd-433b-916b-3e72ee33d1be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.11/dist-packages (0.3.33)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.2.72)\n",
            "Requirement already satisfied: langchain_google_genai in /usr/local/lib/python3.11/dist-packages (2.0.9)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (0.3.6)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (2.10.6)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (4.12.2)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.0.13)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.51)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (1.2.0)\n",
            "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (0.8.4)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (2.160.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (4.25.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (4.67.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (1.26.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_core) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_core) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_core) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain_core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain_core) (2.27.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (1.66.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (4.9)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain_core) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain_core) (2.3.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (3.2.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_core langgraph langchain_google_genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFQMFmgxGRW3"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNWwhc7LGRUe",
        "outputId": "0bf5e05b-e2fc-4845-dd0a-bc1b7f75254b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-f79acf7e-18b7-4455-81e8-d62b43093f0f-0', usage_metadata={'input_tokens': 1, 'output_tokens': 10, 'total_tokens': 11, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "model: ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(model = \"gemini-2.0-flash\", api_key=GEMINI_API_KEY)\n",
        "model.invoke(\"hello\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0BS6jcJGRSM"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import MessagesState\n",
        "\n",
        "class State(MessagesState):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fz2BFV8hGRPu"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import SystemMessage\n",
        "\n",
        "sys_prompt_classify = SystemMessage(content= \"\"\"\n",
        "    Your work is too clasify either this email content is related to Complain, any updation, want to schedule a meeting or\n",
        "    it's a general query? If user query related to Complain then return just \"complain\", if user query related to Meeting or want to discuss something new on call then return \"meeting\",\n",
        "    if user query related to updation of anything then return \"updation\",  or if user query related to General type of query then return \"general\".\n",
        "    ## Rules\n",
        "    analyze the email content efficiently then give the response.\n",
        "    ## return\n",
        "    Always return just 1 word and lowercase.\n",
        "    \"\"\")\n",
        "sys_prompt_complain = SystemMessage(content= \"\"\"Your work is too check from retrival and answer this on the base of knowledge base and user question. or simply says your complain has been registered\"\"\")\n",
        "sys_prompt_meeting = SystemMessage(content= \"\"\"Your work is too say your appointment has been booked. \"\"\")\n",
        "sys_prompt_updation = SystemMessage(content= \"\"\"Your work is too say ok, i'll upate it and get back to you as soon as possible. \"\"\")\n",
        "sys_prompt_general_query = SystemMessage(content= \"\"\"Your work is too say i am a assistant of we build trade one of our team member will reach out you soon and answer your query as best.\"\"\")\n",
        "sys_email_prompt = \"\"\"\n",
        "You are an AI assistant tasked with generating professional email responses.\n",
        "Based on the following content, please compose a polite and concise email response:\n",
        "\n",
        "{content}\n",
        "\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dy7s2D6wOBhb"
      },
      "source": [
        "##### For Classify Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "To81AxmAMoRl"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage,AIMessage\n",
        "from langchain_core.messages import SystemMessage\n",
        "\n",
        "def classify_agent(state: MessagesState) -> str:\n",
        "    \"\"\"\n",
        "    Function to classify a user query using a system prompt and the ChatGoogleGenerativeAI model.\n",
        "\n",
        "    Args:\n",
        "        sys_prompt_classify (str): The system prompt to guide the model's behavior.\n",
        "        user_query (str): The user's query to be classified.\n",
        "\n",
        "    Returns:\n",
        "        str: The model's response to the user query.\n",
        "    \"\"\"\n",
        "    sys_prompt_classify = [SystemMessage(content= \"\"\"\n",
        "    Your work is too clasify either this email content is related to Complain, any updation, want to schedule a meeting or\n",
        "    it's a general query? If user query related to Complain then return just \"complain\", if user query related to Meeting or want to discuss something new on call then return \"meeting\",\n",
        "    if user query related to updation of anything then return \"updation\",  or if user query related to General type of query then return \"general\".\n",
        "    ## Rules\n",
        "    analyze the email content efficiently then give the response.\n",
        "    ## return\n",
        "    Always return just 1 word and lowercase.\n",
        "    \"\"\")]\n",
        "    #The state dictionary stores messages under the key \"messages\"\n",
        "    state1=state[\"messages\"]\n",
        "    # # Initialize the message state with the system prompt and user query\n",
        "    # initial_messages = [\n",
        "    #     SystemMessage(content=sys_prompt_classify),\n",
        "    #     HumanMessage(content=user_query)\n",
        "    # ]\n",
        "    m = sys_prompt_classify + state1\n",
        "\n",
        "    # Invoke the model with the current state messages\n",
        "    response = model.invoke(m)\n",
        "\n",
        "    # Append the AI's response to the message state\n",
        "    state.messages.append(AIMessage(content=response.content))\n",
        "\n",
        "    # Return the AI's response content\n",
        "    return response.content"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "workflow = StateGraph(state_schema=MessagesState)\n",
        "workflow.add_edge(START, \"model\")\n",
        "workflow.add_node(\"model\", classify_agent)\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "hMosRkaJAhIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Hi! I'm Bob.\"\n",
        "\n",
        "input_messages = [HumanMessage(query)]\n",
        "output = app.invoke({\"messages\": input_messages})\n",
        "output[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "TJMIVBtWDkdK",
        "outputId": "892a20ec-4ba2-45f2-92b7-4459912815af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'dict' object has no attribute 'messages'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-169-52b6cbfac4ce>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minput_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mHumanMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_messages\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2067\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2069\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   2070\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1722\u001b[0m                 \u001b[0;31m# with channel updates applied only at the transition between steps.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1724\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   1725\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    231\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m                 )\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_set_config_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-167-472b1b1aa01b>\u001b[0m in \u001b[0;36mclassify_agent\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# Append the AI's response to the message state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAIMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# Return the AI's response content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'messages'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyue5ZGMN1Iv"
      },
      "source": [
        "##### For Complain Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-qgWlq6M5kc"
      },
      "outputs": [],
      "source": [
        "def complaint_agent(state: MessagesState, sys_prompt_complain: str, user_query: str) -> str:\n",
        "    \"\"\"\n",
        "    Handles user complaints by processing the user query with a system prompt and updating the conversation state.\n",
        "\n",
        "    Args:\n",
        "        state (MessagesState): The current conversation state containing the message history.\n",
        "        sys_prompt_complain (str): The system prompt guiding the model's behavior for complaint handling.\n",
        "        user_query (str): The user's complaint query.\n",
        "\n",
        "    Returns:\n",
        "        str: The model's response to the user's complaint.\n",
        "    \"\"\"\n",
        "    # Append the system prompt and user query to the message history\n",
        "    state.messages.append(SystemMessage(content=sys_prompt_complain))\n",
        "    state.messages.append(HumanMessage(content=user_query))\n",
        "\n",
        "    # Invoke the model with the updated message history\n",
        "    response = model.invoke(state.messages)\n",
        "\n",
        "    # Append the AI's response to the message history to maintain context\n",
        "    state.messages.append(AIMessage(content=response.content))\n",
        "\n",
        "    # Return the AI's response content\n",
        "    return response.content\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI84TAWlOkvw"
      },
      "source": [
        "##### For Meeting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2cYYrYYOj1R"
      },
      "outputs": [],
      "source": [
        "def meeting_agent(state: MessagesState, sys_prompt_meeting: str, user_query: str) -> str:\n",
        "    \"\"\"\n",
        "    Processes meeting-related user queries, updates the conversation state, and returns the model's response.\n",
        "\n",
        "    Args:\n",
        "        state (MessagesState): The current conversation state containing the message history.\n",
        "        sys_prompt_meeting (str): The system prompt guiding the model's behavior for meeting-related queries.\n",
        "        user_query (str): The user's query related to meetings.\n",
        "\n",
        "    Returns:\n",
        "        str: The model's response to the user's meeting-related query.\n",
        "    \"\"\"\n",
        "    # Append the system prompt and user query to the message history\n",
        "    state.messages.append(SystemMessage(content=sys_prompt_meeting))\n",
        "    state.messages.append(HumanMessage(content=user_query))\n",
        "\n",
        "    # Invoke the model with the updated message history\n",
        "    response = model.invoke(state.messages)\n",
        "\n",
        "    # Append the AI's response to the message history to maintain context\n",
        "    state.messages.append(AIMessage(content=response.content))\n",
        "\n",
        "    # Return the AI's response content\n",
        "    return response.content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3Xi2I49UvJT"
      },
      "source": [
        "##### For Updation Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vY-Y4iHvOjrl"
      },
      "outputs": [],
      "source": [
        "\n",
        "def update_agent(state: MessagesState, sys_prompt_update: str, user_query: str) -> str:\n",
        "    \"\"\"\n",
        "    Processes update-related user queries, updates the conversation state, and returns the model's response.\n",
        "\n",
        "    Args:\n",
        "        state (MessagesState): The current conversation state containing the message history.\n",
        "        sys_prompt_update (str): The system prompt guiding the model's behavior for update-related queries.\n",
        "        user_query (str): The user's query related to updates.\n",
        "\n",
        "    Returns:\n",
        "        str: The model's response to the user's update-related query.\n",
        "    \"\"\"\n",
        "    # Append the system prompt and user query to the message history\n",
        "    state.messages.append(SystemMessage(content=sys_prompt_updation))\n",
        "    state.messages.append(HumanMessage(content=user_query))\n",
        "\n",
        "    # Invoke the model with the updated message history\n",
        "    response = model.invoke(state.messages)\n",
        "\n",
        "    # Append the AI's response to the message history to maintain context\n",
        "    state.messages.append(AIMessage(content=response.content))\n",
        "\n",
        "    # Return the AI's response content\n",
        "    return response.content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BN5ZPgzRVSZH"
      },
      "source": [
        "##### For General Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqKdah1ZOjil"
      },
      "outputs": [],
      "source": [
        "def general_agent(state: MessagesState, sys_prompt_general: str, user_query: str) -> str:\n",
        "    \"\"\"\n",
        "    Processes general user queries, updates the conversation state, and returns the model's response.\n",
        "\n",
        "    Args:\n",
        "        state (MessagesState): The current conversation state containing the message history.\n",
        "        sys_prompt_general (str): The system prompt guiding the model's behavior for general queries.\n",
        "        user_query (str): The user's general query.\n",
        "\n",
        "    Returns:\n",
        "        str: The model's response to the user's general query.\n",
        "    \"\"\"\n",
        "    # Append the system prompt and user query to the message history\n",
        "    state.messages.append(SystemMessage(content=sys_prompt_general_query))\n",
        "    state.messages.append(HumanMessage(content=user_query))\n",
        "\n",
        "    # Invoke the model with the updated message history\n",
        "    response = model.invoke(state.messages)\n",
        "\n",
        "    # Append the AI's response to the message history to maintain context\n",
        "    state.messages.append(AIMessage(content=response.content))\n",
        "\n",
        "    # Return the AI's response content\n",
        "    return response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxey_BWycQWD"
      },
      "source": [
        "#### For Email Generate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFVCsMm9cPzE"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import SystemMessage, AIMessage\n",
        "from langgraph.graph import MessagesState\n",
        "\n",
        "def email_generation_agent(state: MessagesState, sys_email_prompt: str, agent_response: str) -> str:\n",
        "    \"\"\"\n",
        "    Generates an email response based on the agent's response.\n",
        "\n",
        "    Args:\n",
        "        state (MessagesState): The current conversation state containing the message history.\n",
        "        sys_email_prompt (str): The system prompt guiding the email generation.\n",
        "        agent_response (str): The response from the specialized agent.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated email content.\n",
        "    \"\"\"\n",
        "    # Append the system prompt and agent's response to the message history\n",
        "    state.messages.append(SystemMessage(content=sys_email_prompt))\n",
        "    state.messages.append(AIMessage(content=agent_response))\n",
        "\n",
        "    # Invoke the model with the updated message history\n",
        "    response = model.invoke(state.messages)\n",
        "\n",
        "    # Return the generated email content\n",
        "    return response.content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUle5PJnxTnQ"
      },
      "source": [
        "##### Classify Agent Again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNQ3UzaJxSFK"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "from langgraph.graph import MessagesState\n",
        "\n",
        "def classify_agent(user_query: str, sys_prompt_classify: str) -> AIMessage:\n",
        "    \"\"\"\n",
        "    Function to classify a user query using a system prompt and the ChatGoogleGenerativeAI model.\n",
        "\n",
        "    Args:\n",
        "        user_query (str): The user's query to be classified.\n",
        "        sys_prompt_classify (str): The system prompt to guide the model's behavior.\n",
        "\n",
        "    Returns:\n",
        "        AIMessage: The model's response to the user query.\n",
        "    \"\"\"\n",
        "    # Initialize the message state\n",
        "    state = MessagesState(messages=[])\n",
        "\n",
        "    # Append the system prompt and user query to the message history\n",
        "    state.messages.extend([\n",
        "        SystemMessage(content=sys_prompt_classify),\n",
        "        HumanMessage(content=user_query)\n",
        "    ])\n",
        "\n",
        "    # Invoke the model with the current state messages\n",
        "    response = model.invoke(state.messages)\n",
        "\n",
        "    # Append the AI's response to the message state\n",
        "    state.messages.append(AIMessage(content=response.content))\n",
        "\n",
        "    # Return the AI's response content\n",
        "    return state.messages[-1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQ7IG9g5ZCjE"
      },
      "source": [
        "#### for conditional edge logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIIyzaXCZCFg"
      },
      "outputs": [],
      "source": [
        "def route_based_on_intent(state: MessagesState, sys_prompts: dict, user_query: str) -> str:\n",
        "    \"\"\"\n",
        "    Routes the user query to the appropriate agent based on the classified intent.\n",
        "\n",
        "    Args:\n",
        "        state (MessagesState): The current conversation state containing the message history and intent.\n",
        "        sys_prompts (dict): A dictionary mapping intents to their corresponding system prompts.\n",
        "        user_query (str): The user's query.\n",
        "\n",
        "    Returns:\n",
        "        str: The response from the appropriate agent based on the intent.\n",
        "    \"\"\"\n",
        "    # Retrieve the classified intent from the state\n",
        "    intent = state.get(\"intent\")\n",
        "    print(f\"Current intent: {intent}\")\n",
        "\n",
        "    # Define a mapping of intents to agent functions\n",
        "    agent_functions = {\n",
        "        \"complain\": complaint_agent,\n",
        "        \"meeting\": meeting_agent,\n",
        "        \"updation\": update_agent,\n",
        "        \"general\": general_agent\n",
        "    }\n",
        "\n",
        "    # Select the appropriate agent function based on the intent\n",
        "    agent_function = agent_functions.get(intent)\n",
        "\n",
        "    if agent_function:\n",
        "        # Retrieve the corresponding system prompt\n",
        "        sys_prompt = sys_prompts.get(intent)\n",
        "        if sys_prompt:\n",
        "            # Invoke the selected agent function\n",
        "            response = agent_function(state, sys_prompt, user_query)\n",
        "            return response\n",
        "        else:\n",
        "            print(f\"No system prompt found for intent: {intent}\")\n",
        "            return \"I'm sorry, I don't have a response for that.\"\n",
        "    else:\n",
        "        print(f\"No recognized intent, defaulting to general agent.\")\n",
        "        # Default to the General_Agent if intent is unrecognized\n",
        "        sys_prompt_general = sys_prompts.get(\"general\", \"\")\n",
        "        return general_agent(state, sys_prompt_general, user_query)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuLk3mJ8KCnn"
      },
      "source": [
        "## Node Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dI1ALeA6GRNk",
        "outputId": "46d77a62-d0b6-40dc-c731-d5b2aa30c089"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7cf82a194e50>"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ],
      "source": [
        "from langgraph.prebuilt import ToolNode\n",
        "from langgraph.prebuilt import tools_condition\n",
        "from langgraph.graph import START,END,StateGraph,MessagesState\n",
        "\n",
        "\n",
        "# Build Grafrom langgraph.prebuilt import tools_conditionph\n",
        "builder: StateGraph = StateGraph(state_schema=MessagesState)\n",
        "builder.add_node(\"Classify_Agent\", classify_agent)\n",
        "builder.add_node(\"Complaint_Agent\", complaint_agent)\n",
        "builder.add_node(\"Updation_Agent\", update_agent)\n",
        "builder.add_node(\"Meeting_Agent\", meeting_agent)\n",
        "builder.add_node(\"General_Agent\", general_agent)\n",
        "builder.add_node(\"Email_Generation_Agent\", email_generation_agent)\n",
        "\n",
        "\n",
        "\n",
        "#builder.add_node(\"tools\", ToolNode(tools))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdINxQHsaBFe"
      },
      "source": [
        "#### Graph Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5WNGWkIGRLQ",
        "outputId": "bc462df0-484f-4e3f-9c2a-5af087916d85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7cf82a194e50>"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ],
      "source": [
        "builder.add_edge(START, \"Classify_Agent\")\n",
        "builder.add_conditional_edges(\n",
        "    \"Classify_Agent\",\n",
        "    route_based_on_intent,\n",
        "    {\n",
        "        \"Complaint_Agent\": \"Complaint_Agent\",\n",
        "        \"Meeting_Agent\": \"Meeting_Agent\",\n",
        "        \"Updation_Agent\": \"Updation_Agent\",\n",
        "        \"General_Agent\": \"General_Agent\",\n",
        "    }\n",
        ")\n",
        "# Add edges from each agent to the Email_Generation_Agent\n",
        "builder.add_edge(\"Complaint_Agent\", \"Email_Generation_Agent\")\n",
        "builder.add_edge(\"Meeting_Agent\", \"Email_Generation_Agent\")\n",
        "builder.add_edge(\"Updation_Agent\", \"Email_Generation_Agent\")\n",
        "builder.add_edge(\"General_Agent\", \"Email_Generation_Agent\")\n",
        "\n",
        "# Set the finish point to END\n",
        "builder.add_edge(\"Email_Generation_Agent\", END)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "4J8H71eGGRJE",
        "outputId": "d0a56903-8690-4bde-941e-9c49e55ea5e6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from langgraph.graph.state import CompiledStateGraph\n",
        "graph: CompiledStateGraph = builder.compile()\n",
        "from IPython.display import display, Image\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = 'Write a simple report on how to use Generative AI in Healthcare Sector.'\n",
        "sys_prompt_classify = \"Your system prompt goes here\"  # Replace with your actual system prompt\n",
        "\n",
        "ai_message = classify_agent(user_query, sys_prompt_classify)\n",
        "print(ai_message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "I1ePLJDo_BY4",
        "outputId": "8672d41e-26e6-4daf-c891-f6e2a5398324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'dict' object has no attribute 'messages'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-152-7728233f123f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msys_prompt_classify\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Your system prompt goes here\"\u001b[0m  \u001b[0;31m# Replace with your actual system prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mai_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys_prompt_classify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mai_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-142-8d969a68ff21>\u001b[0m in \u001b[0;36mclassify_agent\u001b[0;34m(sys_prompt_classify, user_query)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Invoke the model with the current state messages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Append the AI's response to the message state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'messages'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the user query\n",
        "user_query = \"Your user query here\"\n",
        "\n",
        "# Create the initial messages\n",
        "initial_messages = [\n",
        "    SystemMessage(content=sys_prompt_classify),\n",
        "    HumanMessage(content=user_query)\n",
        "]\n",
        "\n",
        "# Create the state with the initial messages\n",
        "state = MessagesState(messages=initial_messages)\n",
        "\n",
        "# Invoke the graph with the state\n",
        "response = graph.invoke(state)\n",
        "\n",
        "# Access the response content\n",
        "response_content = response['messages'][-1].content\n",
        "print(response_content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "yz-gP5n95D1b",
        "outputId": "3319b077-4157-4a22-f00a-3821a0d40cb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'user_query'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-290328db6a93>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Invoke the graph with the state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Access the response content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2067\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2069\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   2070\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1722\u001b[0m                 \u001b[0;31m# with channel updates applied only at the transition between steps.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1724\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   1725\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    231\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m                 )\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_set_config_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-110-e877a2d77ee7>\u001b[0m in \u001b[0;36mclassify_agent\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0muser\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \"\"\"\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0muser_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_query'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Extract user_query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;31m# ... (rest of the function remains the same)    # Initialize the message state with the system prompt and user query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     initial_messages = [\n",
            "\u001b[0;31mKeyError\u001b[0m: 'user_query'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CGUXE_OW6f3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "Utaw1uN9GRG-",
        "outputId": "3cb0a2db-f158-4e3c-953e-baa48c534445"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidUpdateError",
          "evalue": "Must write to at least one of ['messages']",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidUpdateError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-90ab00aa783f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Assuming sys_prompt_classify is defined as you had it in your previous code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0muser_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Write a simple report on how to use Generative AI in Healthcare Sector.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'user_query'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muser_query\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2067\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2069\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   2070\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1722\u001b[0m                 \u001b[0;31m# with channel updates applied only at the transition between steps.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1724\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   1725\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    231\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m                 )\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_set_config_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/write.py\u001b[0m in \u001b[0;36m_write\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mwrite\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         ]\n\u001b[0;32m---> 96\u001b[0;31m         self.do_write(\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mwrites\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/write.py\u001b[0m in \u001b[0;36mdo_write\u001b[0;34m(config, writes, require_at_least_one_of)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrequire_at_least_one_of\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mchan\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequire_at_least_one_of\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 raise InvalidUpdateError(\n\u001b[0m\u001b[1;32m    158\u001b[0m                     \u001b[0;34mf\"Must write to at least one of {require_at_least_one_of}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                 )\n",
            "\u001b[0;31mInvalidUpdateError\u001b[0m: Must write to at least one of ['messages']"
          ]
        }
      ],
      "source": [
        "# Assuming sys_prompt_classify is defined as you had it in your previous code\n",
        "user_query = 'Write a simple report on how to use Generative AI in Healthcare Sector.'\n",
        "output = graph.invoke({'user_query': user_query})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "zwfcuMxJGRDm",
        "outputId": "2671bc1d-a610-4e4f-97dd-ce1c79ae17f1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidUpdateError",
          "evalue": "Must write to at least one of ['messages']",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidUpdateError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-129-382b62250c6f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Invoke the graph with the state, not just the user_query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Pass user_query as input instead of state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'user_query'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muser_query\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Access the response content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2067\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2069\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   2070\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1722\u001b[0m                 \u001b[0;31m# with channel updates applied only at the transition between steps.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1724\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   1725\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    231\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m                 )\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_set_config_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/write.py\u001b[0m in \u001b[0;36m_write\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mwrite\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         ]\n\u001b[0;32m---> 96\u001b[0;31m         self.do_write(\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mwrites\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/write.py\u001b[0m in \u001b[0;36mdo_write\u001b[0;34m(config, writes, require_at_least_one_of)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrequire_at_least_one_of\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mchan\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequire_at_least_one_of\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 raise InvalidUpdateError(\n\u001b[0m\u001b[1;32m    158\u001b[0m                     \u001b[0;34mf\"Must write to at least one of {require_at_least_one_of}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                 )\n",
            "\u001b[0;31mInvalidUpdateError\u001b[0m: Must write to at least one of ['messages']"
          ]
        }
      ],
      "source": [
        "# Assuming sys_prompt_classify is defined as you had it in your previous code\n",
        "user_query = 'Write a simple report on how to use Generative AI in Healthcare Sector.'\n",
        "\n",
        "# Create the initial messages\n",
        "initial_messages = [\n",
        "    SystemMessage(content=sys_prompt_classify),  # Include the system prompt\n",
        "    HumanMessage(content=user_query)\n",
        "]\n",
        "\n",
        "# Create the state with the initial messages\n",
        "state = MessagesState(messages=initial_messages)  # Create a MessagesState object\n",
        "\n",
        "# Invoke the graph with the state, not just the user_query\n",
        "# Pass user_query as input instead of state\n",
        "output = graph.invoke({'user_query': user_query})\n",
        "\n",
        "# Access the response content\n",
        "response_content = output['messages'][-1].content\n",
        "print(response_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1ecx5iNOGRBM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDDlcTdVGQ-2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4c21wSyJGQ8H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9F8UTI9zGQ1w"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5gdHepSoci2xSCjrag3R1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}